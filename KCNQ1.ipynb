{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erCMos4LuGpq"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files #one way to import files\n",
        "# uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xExyl3B-0a0_"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.listdir()\n",
        "# !pwd #check working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxBXl0XHt-KR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import sklearn\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # device agnostic code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrCcMXqdyTsB",
        "outputId": "6f3630a2-95ce-4eb1-bd0b-871f37e26407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Peak Current Density  V_1/2  tau_act  tau_deac\n",
            "0                    1.00  1.000     1.00      1.00\n",
            "1                    1.00  1.000     1.00      1.00\n",
            "2                    1.00  1.000     1.00      1.00\n",
            "3                    1.00  1.000     1.00      1.00\n",
            "4                    1.00  1.000     1.00      1.00\n",
            "..                    ...    ...      ...       ...\n",
            "465                  1.59  1.050     1.28      0.99\n",
            "466                  0.22  1.741     1.54       NaN\n",
            "467                  1.00  1.000     1.00      1.00\n",
            "468                  1.00  1.000     1.00      1.00\n",
            "469                  1.00  1.000     1.00      1.00\n",
            "\n",
            "[470 rows x 4 columns]\n",
            "     Peak Current Density  V_1/2  tau_act  tau_deac\n",
            "0                    1.00  1.000     1.00      1.00\n",
            "1                    1.00  1.000     1.00      1.00\n",
            "2                    1.00  1.000     1.00      1.00\n",
            "3                    1.00  1.000     1.00      1.00\n",
            "4                    1.00  1.000     1.00      1.00\n",
            "..                    ...    ...      ...       ...\n",
            "465                  1.59  1.050     1.28      0.99\n",
            "466                  0.22  1.741     1.54      0.00\n",
            "467                  1.00  1.000     1.00      1.00\n",
            "468                  1.00  1.000     1.00      1.00\n",
            "469                  1.00  1.000     1.00      1.00\n",
            "\n",
            "[470 rows x 4 columns]\n",
            "Imported input dataset of shape: torch.Size([470, 12])\n",
            "Imported output dataset of shape: torch.Size([470, 4])\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as py\n",
        "\n",
        "inputs_dataframe = pd.read_csv('full.whet.multimer.csv') #read from working directory\n",
        "inputs_dataframe.drop(inputs_dataframe.columns[[0, 13, 14, 15, 16]], axis=1, inplace=True) #delete variant column and the binary columns at the end\n",
        "outputs_dataframe = pd.read_csv('a1q1.model_data.csv')\n",
        "outputs_dataframe.drop(outputs_dataframe.columns[[0]], axis=1, inplace=True) #delete variant column\n",
        "\n",
        "inputs_dataframe.fillna(0, inplace=True) #replace NaNs with zeros in the input data\n",
        "\n",
        "print(outputs_dataframe) # visualize data before NaN deletion\n",
        "\n",
        "outputs_dataframe.fillna(0, inplace=True) #replace NaNs with zeros in the target data\n",
        "\n",
        "print(outputs_dataframe) # visualize data after NaN deletion\n",
        "\n",
        "inputs_py = inputs_dataframe.to_numpy() #numpy array from dataframe\n",
        "outputs_py = outputs_dataframe.to_numpy()\n",
        "\n",
        "inputs = torch.from_numpy(inputs_py).type(torch.float) #create tensor from numpy array\n",
        "outputs = torch.from_numpy(outputs_py).type(torch.float)\n",
        "\n",
        "print(f\"Imported input dataset of shape: {inputs.shape}\") #confirm tensor shape\n",
        "print(f\"Imported output dataset of shape: {outputs.shape}\")\n",
        "\n",
        "#print(f\"First 20 input rows: {inputs[:20]}\")\n",
        "#print(f\"First 20 output rows: {inputs[:20]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XjC_C3VVgZ_"
      },
      "source": [
        "How to handle NaNs??????"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "btVqMHbVQTf5",
        "outputId": "2318d36b-39a2-48ca-9ede-b3cf126d3926"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-0ac81bbcedcc>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mKCNQ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Create the model using 32 units in the hidden layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mKCNQ5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The parameters: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKCNQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#print starting parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-0ac81bbcedcc>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_features, output_features, hidden_units)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     self.layer_stack = nn.Sequential(\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mreset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# https://github.com/pytorch/pytorch/issues/57109\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mfan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/init.py\u001b[0m in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m  \u001b[0;31m# Calculate uniform bounds from standard deviation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details."
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True) # make model directory to save models to\n",
        "\n",
        "class Model(nn.Module): #create NN class\n",
        "  def __init__(self, input_features, output_features, hidden_units):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Linear(in_features=input_features, out_features=hidden_units),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout(0.25),\n",
        "        nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout(0.25),\n",
        "        nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Linear(in_features=hidden_units, out_features=output_features)\n",
        "    )\n",
        "        \n",
        "  def forward(self, x):\n",
        "    return self.layer_stack(x)\n",
        "\n",
        "KCNQ=Model(input_features=inputs.size(1), output_features=outputs.size(1), hidden_units=32).to(device) #Create the model using 32 units in both hidden layers\n",
        "KCNQ5=Model(input_features=inputs.size(1), output_features=outputs.size(1), hidden_units=32).to(device) #Create a model named KCNQ5 which was the intended averaged model of the\n",
        "# k-fold cross validation as the averaged parameters of k=0 ... k=3 would be averaged for the k=4 fold of the dataset. The models whose parameters would be averaged\n",
        "# would be saved as KCNQ1 through KCNQ4 and therefore the averaged one would be KCNQ5\n",
        "\n",
        "print(\"The parameters: \", list(KCNQ.parameters())) #print starting parameters \n",
        "\n",
        "MODEL_NAME = \"KCNQStarter.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\") #save the starting parameters to reset with each interation of k through the cross validation\n",
        "torch.save(obj=KCNQ.state_dict(), f=MODEL_SAVE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ok4hN1Cs7Dpp"
      },
      "outputs": [],
      "source": [
        "# class AltModel(nn.Module): #another way to define the NN\n",
        "#   def __init__(self, input_features, output_features, hidden_units):\n",
        "#     super().__init__()\n",
        "#     self.layer_1 = nn.Linear(in_features=input_features, out_features=hidden_units)\n",
        "#     self.layer_2 = nn.Linear(in_features=hidden_units, out_features=hidden_units)\n",
        "#     self.layer_3 = nn.Linear(in_features=hidden_units, out_features=output_features)\n",
        "#     self.relu = nn.LeakyReLU()\n",
        "\n",
        "#   def forward(self, x):\n",
        "#     return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))\n",
        "\n",
        "# KCNQ_Model2 = AltModel(input_features=inputs.size(1), output_features=outputs.size(1), hidden_units=inputs.size(1)).to(device)\n",
        "\n",
        "# # print(\"The parameters: \", list(KCNQ_Model2.parameters()))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfmVt4i1RUJv"
      },
      "outputs": [],
      "source": [
        "#loss_fn = nn.MSELoss()\n",
        "loss_fn = nn.SmoothL1Loss() # selecting the loss function\n",
        "optimizer = torch.optim.SGD(params=KCNQ.parameters(), lr=0.01) # selecting the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaA5z0SYWauL"
      },
      "outputs": [],
      "source": [
        "# train test split of the data as 80/20 for my first attempt at training this model\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# input_train, input_test, output_train, output_test = train_test_split(inputs, outputs, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7LBezg7ZN-A"
      },
      "outputs": [],
      "source": [
        "# code to train the model as a 80/20 train test split\n",
        "\n",
        "# torch.manual_seed(42)\n",
        "\n",
        "# epochs = 10000\n",
        "\n",
        "# epoch_count = [] #empty tensors that can be appended as you run through the epochs\n",
        "# loss_values = []\n",
        "# test_loss_values = []\n",
        "\n",
        "# input_train, output_train = input_train.to(device), output_train.to(device) #make sure the data are on the selected device (either GPU or CPU)\n",
        "# input_test, output_test = input_test.to(device), output_test.to(device)\n",
        "\n",
        "# for epoch in range(epochs):\n",
        "#   KCNQ.train()\n",
        "\n",
        "#   output_preds = KCNQ(input_train) #generate output preditions\n",
        "  \n",
        "#   loss = loss_fn(output_preds, output_train) #calculate loss\n",
        "#   loss_values.append(loss.item()) #save the loss of this epoch\n",
        "\n",
        "#   optimizer.zero_grad() #zero the optimizer\n",
        "\n",
        "#   loss.backward() #backpropagation\n",
        "\n",
        "#   optimizer.step() #gradient descent\n",
        "\n",
        "#   KCNQ.eval() #set the model to eval mode\n",
        "\n",
        "\n",
        "\n",
        "#   with torch.inference_mode():\n",
        "#     test_preds = KCNQ(input_test) #generate test prediction with this epoch's model parameters\n",
        "#     test_loss = loss_fn(test_preds, output_test) #calculate test loss with this epoch's model parameters\n",
        "#     epoch_count.append(epoch) #save the epoch count\n",
        "#     #loss_values.append(loss) #save the training loss, commented out because it was moved above\n",
        "#     test_loss_values.append(test_loss) # save the test loss\n",
        "\n",
        "#   if epoch % 1000 == 0:\n",
        "    \n",
        "#     print(f\"Epoch: {epoch} | Loss: {loss:.4f} | Test loss: {test_loss:.4f}\") \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the training and test losses as a function of epoch\n",
        "\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.plot(epoch_count, np.array(torch.tensor(loss_values).numpy()), label=\"Train loss\")\n",
        "# plt.plot(epoch_count, torch.Tensor(test_loss_values), label=\"Test loss\")\n",
        "# plt.title(\"Training and test loss curves\")\n",
        "# plt.xlabel(\"Epochs\")\n",
        "# plt.ylabel(\"Normalized Loss\")\n",
        "# plt.legend();\n"
      ],
      "metadata": {
        "id": "Nv2MHOn_WMeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gykma8mOIJxb"
      },
      "outputs": [],
      "source": [
        "# just visualizing the test predictions versus the actual test data\n",
        "\n",
        "# with torch.inference_mode():\n",
        "#   test_preds = KCNQ(input_test)\n",
        "# test_preds[:10], output_test[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iec8uYA9_cBJ"
      },
      "outputs": [],
      "source": [
        "# similar comparison\n",
        "\n",
        "# a = output_preds[295:300]\n",
        "# b = output_train[295:300]\n",
        "# print(a)\n",
        "# print(b)\n",
        "# loss = loss_fn(a, b)\n",
        "# print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "lJlkkB-yYvn3",
        "outputId": "44145778-578c-4a22-b16a-7cc7b79e6f60"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-29c64bfbd3b6>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[0mKCNQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m       \u001b[0moutput_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKCNQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_train_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_train_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-0ac81bbcedcc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# KCNQ=Model(input_features=inputs.size(1), output_features=outputs.size(1), hidden_units=inputs.size(1)).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Inference tensors cannot be saved for backward. To work around you can make a clone to get a normal tensor and use it in autograd."
          ]
        }
      ],
      "source": [
        "# implementing the model using k-fold cross validation\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "LOAD_MODEL_NAME = \"KCNQStarter.pth\" #above the starting random model parameters were saved as this\n",
        "\n",
        "MODEL_LOAD_PATH = MODEL_PATH / LOAD_MODEL_NAME\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "epochs = 10000\n",
        "\n",
        "n_splits = 5\n",
        "\n",
        "epoch_count = torch.zeros(epochs,1) #setting up tensors of appropriate size based on the number of splits (k)\n",
        "loss_values = torch.zeros(epochs,n_splits-1)\n",
        "test_loss_values = torch.zeros(epochs,n_splits-1)\n",
        "\n",
        "input_train_splits = torch.zeros(int((inputs.size(0)*(n_splits-1))/n_splits), inputs.size(1), n_splits) #setting up tensors of appropriate size based on the number of splits (k)\n",
        "input_test_splits = torch.zeros(int(inputs.size(0)/n_splits), inputs.size(1), n_splits) \n",
        "\n",
        "output_train_splits = torch.zeros(int((outputs.size(0)*(n_splits-1))/n_splits), outputs.size(1), n_splits) #setting up tensors of appropriate size based on the number of splits (k)\n",
        "output_test_splits = torch.zeros(int(outputs.size(0)/n_splits), outputs.size(1), n_splits)\n",
        "\n",
        "#print(input_train_splits.shape)\n",
        "#print(input_test_splits.shape)\n",
        "\n",
        "kf = KFold(n_splits, random_state=42, shuffle=True)\n",
        "kf.get_n_splits(inputs)\n",
        "\n",
        "# print(kf)\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(kf.split(inputs)): #theoretically this should be retrieving every train and test index in each split as specified by KFold, i think this might be where the issue is\n",
        "  #print(f\"Fold {i}:\")\n",
        "  #print(f\"  Train: index={train_index}\")\n",
        "  #print(f\"  Test:  index={test_index}\")\n",
        "  \n",
        "  input_train_splits[:,:,i] = torch.index_select(inputs, 0, torch.from_numpy(train_index)) # this should be assigning all of the input train and test splits the values from the appropriate indices\n",
        "  #print(train_splits[:,:,i])\n",
        "  input_test_splits[:,:,i] = torch.index_select(inputs, 0, torch.from_numpy(test_index))\n",
        "  output_train_splits[:,:,i] = torch.index_select(outputs, 0, torch.from_numpy(train_index))\n",
        "  output_test_splits[:,:,i] = torch.index_select(outputs, 0, torch.from_numpy(test_index))\n",
        "\n",
        "  if i != 4:\n",
        "    for epoch in range(epochs):\n",
        "      #KCNQ.load_state_dict(torch.load(f=MODEL_LOAD_PATH))\n",
        "      KCNQ.train()\n",
        "\n",
        "      output_preds = KCNQ(input_train_splits[:,:,i]) #similar implementation as the 80/20 train test split model as above\n",
        "      \n",
        "      loss = loss_fn(output_preds, output_train_splits[:,:,i])\n",
        "      loss_values[epoch,i-1] = loss\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      loss.backward() #backpropagation\n",
        "\n",
        "      optimizer.step() #gradient descent\n",
        "\n",
        "      KCNQ.eval()\n",
        "\n",
        "      with torch.inference_mode():\n",
        "        test_preds = KCNQ(input_test_splits[:,:,i])\n",
        "        test_loss = loss_fn(test_preds, output_test_splits[:,:,i])\n",
        "        test_loss_values[epoch,i] = test_loss\n",
        "\n",
        "      if epoch % 2000 == 0:\n",
        "        print(f\"Epoch: {epoch} | Loss: {loss:.4f} | Test loss: {test_loss:.4f}\")\n",
        "\n",
        "      if epoch % 9999 == 0 and epoch != 0 : # this was my attempt to save the parameters of each model on the i=9999 (10000th) epoch as a separate model\n",
        "        MODEL_NAME = str.join('.', ('KCNQ_Model', str(i), 'pth'))\n",
        "        MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "        #print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "        torch.save(obj=KCNQ.state_dict(), f=MODEL_SAVE_PATH)\n",
        "\n",
        "        KCNQ.load_state_dict(torch.load(f=MODEL_LOAD_PATH))\n",
        "  else:\n",
        "    print(\"hi\")\n",
        "    # KCNQ1 = Model(input_features=inputs.size(1), output_features=outputs.size(1), hidden_units=inputs.size(1)).to(device) # this was my attempt to load the parameters of each model as above and then average them into one model termed KCNQ5 \n",
        "    # MODEL_SAVE_PATH = MODEL_PATH / 'KCNQ_Model.0.pth'\n",
        "    # KCNQ1.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
        "    # KCNQ1.to(device)\n",
        "    # KCNQ2 = Model(input_features=inputs.size(1), output_features=outputs.size(1), hidden_units=inputs.size(1)).to(device)\n",
        "    # MODEL_SAVE_PATH = MODEL_PATH / 'KCNQ_Model.1.pth'\n",
        "    # KCNQ2.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
        "    # KCNQ2.to(device)\n",
        "    # KCNQ3 = Model(input_features=inputs.size(1), output_features=outputs.size(1), hidden_units=inputs.size(1)).to(device)\n",
        "    # MODEL_SAVE_PATH = MODEL_PATH / 'KCNQ_Model.2.pth'\n",
        "    # KCNQ3.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
        "    # KCNQ3.to(device)\n",
        "    # KCNQ4 = Model(input_features=inputs.size(1), output_features=outputs.size(1), hidden_units=inputs.size(1)).to(device)\n",
        "    # MODEL_SAVE_PATH = MODEL_PATH / 'KCNQ_Model.3.pth'\n",
        "    # KCNQ4.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
        "    # KCNQ4.to(device)\n",
        "\n",
        "    # #print(f\"Loss values: {loss_values[:5]}\")\n",
        "\n",
        "    # beta = 0.5 # interpolation parameter    \n",
        "    # params1 = KCNQ1.named_parameters()\n",
        "    # params2 = KCNQ2.named_parameters()\n",
        "    # params3 = KCNQ3.named_parameters()\n",
        "    # params4 = KCNQ4.named_parameters()\n",
        "\n",
        "    # dict_params2 = dict(params2)\n",
        "    # dict_params4 = dict(params4)\n",
        "\n",
        "    # for name1, param1 in params1:\n",
        "    #   if name1 in dict_params2:\n",
        "    #       dict_params2[name1].data.copy_(beta*param1.data + (1-beta)*dict_params2[name1].data)\n",
        "\n",
        "    # print(params1)\n",
        "\n",
        "    # for name1, param1 in params3:\n",
        "    #   if name1 in dict_params4:\n",
        "    #       dict_params4[name1].data.copy_(beta*param1.data + (1-beta)*dict_params4[name1].data)\n",
        "\n",
        "    # for name1, param1 in dict_params2:\n",
        "    #   if name1 in dict_params4:\n",
        "    #       dict_params4[name1].data.copy_(beta*param1.data + (1-beta)*dict_params4[name1].data)\n",
        "\n",
        "    # KCNQ5.load_state_dict(dict_params4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xR2KsbfeFnDu"
      },
      "outputs": [],
      "source": [
        "# with torch.inference_mode():\n",
        "#   output_preds_new = KCNQ()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}